{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add 30% of null, duplicate and outliers at dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "project_directory = os.path.abspath(os.path.join(current_directory, '..'))\n",
    "if project_directory not in sys.path:\n",
    "    sys.path.append(project_directory)\n",
    "\n",
    "import ML_algorithms\n",
    "import sanity_checks_methods\n",
    "import pandas as pd\n",
    "\n",
    "duplicates_directory = os.path.join(project_directory, 'duplicates')\n",
    "if duplicates_directory not in sys.path:\n",
    "    sys.path.append(duplicates_directory)\n",
    "\n",
    "import duplicates_utils\n",
    "\n",
    "duplicates_directory = os.path.join(project_directory, 'null_dataset')\n",
    "if duplicates_directory not in sys.path:\n",
    "    sys.path.append(duplicates_directory)\n",
    "\n",
    "import null_utility\n",
    "\n",
    "duplicates_directory = os.path.join(project_directory, 'outliers')\n",
    "if duplicates_directory not in sys.path:\n",
    "    sys.path.append(duplicates_directory)\n",
    "\n",
    "import outliers_utils\n",
    "\n",
    "dataset_path = os.path.join(project_directory, 'dataset/stroke_data.csv')\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "no_stroke_group = df[df['stroke'] == 0]\n",
    "stroke_group = df[df['stroke'] == 1]\n",
    "\n",
    "group_size = 5000\n",
    "\n",
    "sampled_no_stroke_group = no_stroke_group.sample(n=group_size, random_state=42)\n",
    "sampled_stroke_group = stroke_group.sample(n=group_size, random_state=42)\n",
    "\n",
    "df = pd.concat([sampled_no_stroke_group,sampled_stroke_group])\n",
    "\n",
    "df = sanity_checks_methods.clean_dataset(df)\n",
    "df_original = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirty the most important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = duplicates_utils.replace_duplicates_values(df, 30)\n",
    "indices, original_values = null_utility.add_null_values(df,'avg_glucose_level', 30)\n",
    "df = outliers_utils.outliers_replace(df, 'avg_glucose_level', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "y_pred_prob_dt, y_test_dt, decision_tree = ML_algorithms.model_dt(df, df_original)\n",
    "mean_accuracy_dt, confidence_interval_dt = ML_algorithms.k_fold_cross_validation_dt(decision_tree,df_original)\n",
    "    \n",
    "print('\\n PRINT SVM PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "y_pred_prob_svm, y_test_svm, svm = ML_algorithms.model_svm(df, df_original)\n",
    "mean_accuracy_svm, confidence_interval_svm = ML_algorithms.k_fold_cross_validation_dt(svm,df_original) \n",
    "    \n",
    "df.loc[indices, 'avg_glucose_level'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algorithms.plot_roc_curve_conlusion(y_pred_prob_dt, y_test_dt, y_pred_prob_svm, y_test_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = [\n",
    "    ('Decision Tree', mean_accuracy_dt, confidence_interval_dt),\n",
    "    ('Support Vector Machine', mean_accuracy_svm, confidence_interval_svm)\n",
    "]\n",
    "ML_algorithms.plot_confidence_intervals(model_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
