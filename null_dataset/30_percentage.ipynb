{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sanity_checks_methods\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from time import time\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "import ML_algorithms\n",
    "import scipy.stats as st\n",
    "\n",
    "df = pd.read_csv('dataset/stroke_data.csv')\n",
    "\n",
    "no_stroke_group = df[df['stroke'] == 0]\n",
    "stroke_group = df[df['stroke'] == 1]\n",
    "\n",
    "group_size = 5000\n",
    "\n",
    "sampled_no_stroke_group = no_stroke_group.sample(n=group_size, random_state=42)\n",
    "sampled_stroke_group = stroke_group.sample(n=group_size, random_state=42)\n",
    "\n",
    "df = pd.concat([sampled_no_stroke_group,sampled_stroke_group])\n",
    "df_to_test = df.copy()\n",
    "df_to_test.dropna(axis=0,inplace=True)\n",
    "df_to_test = df_to_test[df_to_test['sex'] >= 0]\n",
    "\n",
    "\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df = df[df['sex'] >= 0]\n",
    "\n",
    "sanity_checks_methods.drop_negative_age(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 30% TO FEATURE: SEX')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'sex', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'sex'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 30% to age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 30% TO FEATURE: AGE')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'age', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'age'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 30% null values to hypertension feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 30% TO FEATURE: HYPERTENSION')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'hypertension', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'hypertension'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 10% null values to heart_disease feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 30% TO FEATURE: HEART_DISEASE')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'heart_disease', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'heart_disease'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 30% null values to ever_married feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 30% TO FEATURE: EVER_MARRIED')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'ever_married', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'ever_married'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 30% null values to work_type feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 30% TO FEATURE: WORK_TYPE')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'work_type', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'work_type'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 30% null values to residence_type feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 30% TO FEATURE: RESIDENCE_TYPE')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'Residence_type', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'Residence_type'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 30% null values to avg_glucose_level feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 30% TO FEATURE: AVG_GLUCOSE_LEVEL')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'avg_glucose_level', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'avg_glucose_level'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 10% null values to bmi feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 10% TO FEATURE: BMI')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'bmi', 10)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'bmi'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding 30% null values to smoking_status feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ADDING 10% TO FEATURE: SMOKING_STATUS')\n",
    "print('--------------------------------------')\n",
    "indices, original_values = sanity_checks_methods.add_null_values(df,'smoking_status', 30)\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df, df_to_test)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "df.loc[indices, 'smoking_status'] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 30% of null values in the two most important features together (bmi, avg_glucose_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'bmi', 'avg_glucose_level']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df,feature,30)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 30% of null values in the two less important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'sex', 'age']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 30)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 30% of null values in health related features (avg_glucose_level, bmi, hypertension, smoking_status, heart_disease, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'avg_glucose_level', 'age', 'bmi', 'hypertension', 'smoking_status', 'heart_disease']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 30)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inserting 30% of null values in NOT health related features (sex, residence_type, ever_married, work_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'sex', 'residence_type', 'ever_married', 'work_type']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 30)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
