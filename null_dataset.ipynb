{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sanity_checks_methods\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from time import time\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "import ML_algorithms\n",
    "\n",
    "df = pd.read_csv('dataset/stroke_data.csv')\n",
    "\n",
    "no_stroke_group = df[df['stroke'] == 0]\n",
    "stroke_group = df[df['stroke'] == 1]\n",
    "\n",
    "group_size = 5000\n",
    "\n",
    "sampled_no_stroke_group = no_stroke_group.sample(n=group_size, random_state=42)\n",
    "sampled_stroke_group = stroke_group.sample(n=group_size, random_state=42)\n",
    "\n",
    "df = pd.concat([sampled_no_stroke_group,sampled_stroke_group])\n",
    "df = df.dropna()\n",
    "df = df[df['sex'] >= 0]\n",
    "\n",
    "sanity_checks_methods.drop_negative_age(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 10% of null values in every feature separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(f'ADDING 10% TO FEATURE: {column}')\n",
    "    print('--------------------------------------')\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df,column, 10)\n",
    "    \n",
    "    print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "    print('---------------------------------------------------')\n",
    "    decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "    ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "    print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "    print('---------------------------------------------------')\n",
    "    hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "    ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "    df.loc[indices, column] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 30% of null values in every feature separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(f'ADDING 30% TO FEATURE: {column}')\n",
    "    print('--------------------------------------')\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df,column, 30)\n",
    "    \n",
    "    print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "    print('---------------------------------------------------')\n",
    "    decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "    ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "    print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "    print('---------------------------------------------------')\n",
    "    hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "    ML_algorithms.k_fold_cross_validation_dt(hgb,df) \n",
    "    \n",
    "    df.loc[indices, column] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 50% of null values in every feature separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(f'ADDING 50% TO FEATURE: {column}')\n",
    "    print('--------------------------------------')\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df,column, 50)\n",
    "    \n",
    "    print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "    print('---------------------------------------------------')\n",
    "    decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "    ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "    \n",
    "    print('\\n PRINT HGB PREDICTIONS AND RESULTS')\n",
    "    print('---------------------------------------------------')\n",
    "    hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "    ML_algorithms.k_fold_cross_validation_dt(hgb,df)    \n",
    "    \n",
    "    df.loc[indices, column] = original_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 10% of null values in the two most important features together (bmi, avg_glucose_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'bmi', 'avg_glucose_level']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df,feature,10)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 30% of null values in the two most important feature (bmi, avg_glucose_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'bmi', 'avg_glucose_level']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df,feature,30)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 50% of null values in the two most important feature (bmi, avg_glucose_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'bmi', 'avg_glucose_level']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df,feature,50)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 10% of null values in the two less important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'sex', 'age']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 10)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 30% of null values in the two less important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'sex', 'age']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 30)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 50% null values in the two less important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'sex', 'age']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 50)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 10% of null values in health related features (avg_glucose_level, bmi, hypertension, smoking_status, heart_disease, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'avg_glucose_level', 'age', 'bmi', 'hypertension', 'smoking_status', 'heart_disease']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 10)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 30% of null values in health related features (avg_glucose_level, bmi, hypertension, smoking_status, heart_disease, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'avg_glucose_level', 'age', 'bmi', 'hypertension', 'smoking_status', 'heart_disease']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 30)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting 50% of null values in health related features (avg_glucose_level, bmi, hypertension, smoking_status, heart_disease, age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'avg_glucose_level', 'age', 'bmi', 'hypertension', 'smoking_status', 'heart_disease']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 50)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inserting 10% of null values in NOT health related features (sex, residence_type, ever_married, work_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'sex', 'residence_type', 'ever_married', 'work_type']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 10)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inserting 30% of null values in NOT health related features (sex, residence_type, ever_married, work_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'sex', 'residence_type', 'ever_married', 'work_type']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 30)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inserting 50% of null values in NOT health related features (sex, residence_type, ever_married, work_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_dict = {}\n",
    "original_values_dict = {}\n",
    "features = [ 'sex', 'residence_type', 'ever_married', 'work_type']\n",
    "\n",
    "for feature in features:\n",
    "    indices, original_values = sanity_checks_methods.add_null_values(df, feature, 50)\n",
    "    indices_dict[feature] = indices\n",
    "    original_values_dict[feature] = original_values\n",
    "\n",
    "sanity_checks_methods.print_null_duplicates_values(df)\n",
    "\n",
    "print('\\n DECISION TREE PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "\n",
    "decision_tree = ML_algorithms.train_decision_tree_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(decision_tree,df)\n",
    "\n",
    "print('\\n HGB PREDICTIONS AND RESULTS')\n",
    "print('---------------------------------------------------')\n",
    "hgb = ML_algorithms.train_hist_gradient_boosting_model(df)\n",
    "ML_algorithms.k_fold_cross_validation_dt(hgb,df)\n",
    "\n",
    "for feature in features:\n",
    "    df.loc[indices_dict[feature], feature] = original_values_dict[feature]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
